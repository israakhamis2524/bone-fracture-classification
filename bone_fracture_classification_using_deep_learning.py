# -*- coding: utf-8 -*-
"""Bone Fracture Classification using Deep Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GNywbniECZlgyuwEDOdJGvCCwAKrx-64
"""

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp /content/kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d orvile/simple-vs-comminuted-fractures-x-ray-data

!unzip simple-vs-comminuted-fractures-x-ray-data.zip -d bone_fracture_dataset

import os
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

import os, shutil
from sklearn.model_selection import train_test_split

base_dir = "/content/bone_fracture_dataset/augmented_dataset"
os.makedirs(base_dir, exist_ok=True)

classes = ["Comminuted Bone Fracture", "Simple Bone Fracture"]

original_aug_path = "/content/bone_fracture_dataset/Bone Fracture X-ray Dataset Simple vs. Comminuted Fractures/Bone Fracture X-ray Dataset Simple vs. Comminuted Fractures/Bone Fracture/Bone Fracture/Augmented"

for cls in classes:
    src_dir = os.path.join(original_aug_path, cls)
    imgs = os.listdir(src_dir)

    train_imgs, temp_imgs = train_test_split(imgs, test_size=0.3, random_state=42)
    val_imgs, test_imgs = train_test_split(temp_imgs, test_size=0.5, random_state=42)

    for split, split_imgs in zip(["train", "val", "test"], [train_imgs, val_imgs, test_imgs]):
        split_dir = os.path.join(base_dir, split, cls)
        os.makedirs(split_dir, exist_ok=True)

        for img in split_imgs:
            src_path = os.path.join(src_dir, img)
            dst_path = os.path.join(split_dir, img)
            shutil.copyfile(src_path, dst_path)

print("âœ… ØªÙ… Ø§Ù„ØªÙ‚Ø³ÙŠÙ… Ø¥Ù„Ù‰ train / val / test")

train_path = "/content/bone_fracture_dataset/augmented_dataset/train"
val_path   = "/content/bone_fracture_dataset/augmented_dataset/val"
test_path  = "/content/bone_fracture_dataset/augmented_dataset/test"

import os

for root, dirs, files in os.walk("/content"):
    print(root)

img_size = (224, 224)
batch_size = 32

train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)
val_datagen   = ImageDataGenerator(preprocessing_function=preprocess_input)
test_datagen  = ImageDataGenerator(preprocessing_function=preprocess_input)

train_generator = train_datagen.flow_from_directory(
    train_path,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical'
)

val_generator = val_datagen.flow_from_directory(
    val_path,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical'
)

test_generator = test_datagen.flow_from_directory(
    test_path,
    target_size=img_size,
    batch_size=32,
    class_mode='categorical',
    shuffle=False
)

import os
import random
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

base_dir = "/content/bone_fracture_dataset/augmented_dataset/test"

categories = os.listdir(base_dir)

random_category = random.choice(categories)

category_path = os.path.join(base_dir, random_category)

random_image = random.choice(os.listdir(category_path))

image_path = os.path.join(category_path, random_image)

img = mpimg.imread(image_path)
plt.imshow(img)
plt.axis('off')
plt.title(f"Class: {random_category}")
plt.show()

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg


folder_path = "/content/bone_fracture_dataset/augmented_dataset/test/Simple Bone Fracture"
image_names = os.listdir(folder_path)[:6]

plt.figure(figsize=(15, 8))
for i, image_name in enumerate(image_names):
    img_path = os.path.join(folder_path, image_name)
    img = mpimg.imread(img_path)
    plt.subplot(2, 3, i+1)
    plt.imshow(img)
    plt.axis('off')
    plt.title(image_name)

plt.tight_layout()
plt.show()

base_dir = "/content/bone_fracture_dataset/augmented_dataset"
classes = ["Comminuted Bone Fracture", "Simple Bone Fracture"]

for split in ['train', 'val', 'test']:
    print(f"\nğŸ”¹ {split.upper()}")
    for cls in classes:
        path = os.path.join(base_dir, split, cls)
        print(f"{cls}: {len(os.listdir(path))} ØµÙˆØ±")

base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))
base_model.trainable = False

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.3)(x)
x = Dense(128, activation='relu')(x)
x = Dropout(0.3)(x)
predictions = Dense(2, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=predictions)
model.compile(optimizer=Adam(learning_rate=1e-4),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(
    train_generator,
    validation_data=val_generator,

    epochs=25
)

loss, accuracy = model.evaluate(test_generator)
print(f"\nâœ… Test Accuracy: {accuracy*100:.2f}%")

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Accuracy Curve')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)

plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Loss Curve')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

model.save("best_model.h5")

!pip install streamlit pyngrok

!rm -rf /root/.ngrok2

!ngrok config add-authtoken 30ebOnyKYgmtsk6i4PZksRVjPEh_7qgve6zrdGc8w9dG5D3kP

with open("app.py", "w") as f:
    f.write('''
import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input
import numpy as np
from PIL import Image

model = load_model("/content/best_model.h5")
class_names = ['Comminuted Bone Fracture', 'Simple Bone Fracture']

st.set_page_config(page_title="Bone Fracture Classifier", layout="centered")
st.title("ğŸ”¬ Bone Fracture Classification using Deep Learning")

st.write("Ù„Ù„ØªØµÙ†ÙŠÙ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ø§Ù„Ø£Ø´Ø¹Ø©")

uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø©", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    img = Image.open(uploaded_file).convert('RGB')
    st.image(img, caption='Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªÙ… Ø±ÙØ¹Ù‡Ø§', use_column_width=True)

    img = img.resize((224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)

    prediction = model.predict(img_array)
    class_idx = np.argmax(prediction)
    predicted_label = class_names[class_idx]
    confidence = prediction[0][class_idx]

    for i, prob in enumerate(prediction[0]):
        st.write(f"{class_names[i]}: {prob*100:.2f}%")

    st.success(f"âœ… Ø§Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹: **{predicted_label}**")
    st.info(f"ğŸ” Ù†Ø³Ø¨Ø© Ø§Ù„Ø«Ù‚Ø©: {confidence*100:.2f}%")
''')

import os
import threading
import time
from pyngrok import ngrok

ngrok.kill()

def run_app():
    os.system("streamlit run app.py")

thread = threading.Thread(target=run_app)
thread.start()

time.sleep(10)

public_url = ngrok.connect(addr="8501", proto="http")
print("ğŸŒ Ø±Ø§Ø¨Ø· Ø§Ù„ØªØ·Ø¨ÙŠÙ‚:", public_url)